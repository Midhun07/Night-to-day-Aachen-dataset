{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Night-to-day.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5D0E-YetU3y"
      },
      "source": [
        "## <center> **Deep learning Project** </center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5F7CsYR9k8k",
        "outputId": "b73d59f3-88a3-48f7-e1a3-a2129a630ba4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXvIuabntsuf"
      },
      "source": [
        "## <center> **Night to Day image conversion** <center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enxqvpPiVYIt"
      },
      "source": [
        "!unzip -d /content/drive/MyDrive/Colab\\ Notebooks/datasets/data/ /content/drive/MyDrive/Colab\\ Notebooks/datasets/archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB4eIvz1YV_i"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "day_path = '/content/drive/MyDrive/Colab Notebooks/datasets/data/day/day/'\n",
        "night_path = '/content/drive/MyDrive/Colab Notebooks/datasets/data/night/night/'\n",
        "\n",
        "day_files = os.listdir('/content/drive/MyDrive/Colab Notebooks/datasets/data/day/day/')\n",
        "night_files = os.listdir('/content/drive/MyDrive/Colab Notebooks/datasets/data/night/night/')\n",
        "\n",
        "test_loc_day = '/content/drive/MyDrive/Colab Notebooks/datasets/test/day/'\n",
        "test_loc_night = '/content/drive/MyDrive/Colab Notebooks/datasets/test/night/'\n",
        "\n",
        "day_files.sort()\n",
        "night_files.sort()\n",
        "\n",
        "train_files_day = day_files[:10000]\n",
        "test_files_day = day_files[10000:]\n",
        "train_files_night = night_files[:10000]\n",
        "test_files_night = night_files[10000:]\n",
        "\n",
        "for file in test_files_day:\n",
        "  shutil.move(day_path + file, test_loc_day)\n",
        "\n",
        "for file in test_files_night:\n",
        "  shutil.move(night_path + file, test_loc_night)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1LjJsYCtP2R"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import os\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUlXtXtVwuYc"
      },
      "source": [
        "### Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UelO7NM5wuCh"
      },
      "source": [
        "class NDdataset(Dataset):\n",
        "  def __init__(self, day_path, night_path, tfs):\n",
        "    self.day_path = day_path\n",
        "    self.night_path = night_path\n",
        "    self.transforms = tfs\n",
        "    self.day_images = os.listdir(day_path)\n",
        "    self.day_images.sort()\n",
        "    self.night_images = os.listdir(night_path)\n",
        "    self.night_images.sort() \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.day_images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    day = Image.open(self.day_path + self.day_images[idx])\n",
        "    night = Image.open(self.night_path + self.night_images[idx])\n",
        "\n",
        "    day = self.transforms(day)\n",
        "    night = self.transforms(night)\n",
        "\n",
        "    return day, night"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCCn0wAdDdTB"
      },
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/datasets/data/'\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "tfs = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "     transforms.Resize((256, 256))]\n",
        ")\n",
        "dataset = NDdataset(path + 'day/day/', path + 'night/night/', tfs)\n",
        "data_loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ordkBIPDrjS6"
      },
      "source": [
        "class NDtestset(Dataset):\n",
        "  def __init__(self, path, tfs):\n",
        "    self.path = path\n",
        "    self.transforms = tfs\n",
        "    self.night_images = os.listdir(path)\n",
        "    self.night_images.sort() \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.night_images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    night = Image.open(self.path + self.night_images[idx])\n",
        "    night = self.transforms(night)\n",
        "\n",
        "    return night"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLNzXTjjsLQq"
      },
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/datasets/test/night/'\n",
        "batch_size = 100\n",
        "\n",
        "tfs = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "     transforms.Resize((256, 256))]\n",
        ")\n",
        "testset = NDtestset(path, tfs)\n",
        "test_loader = DataLoader(testset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XidfO52kvI_B"
      },
      "source": [
        "### The discriminator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TkibDxsvBPG"
      },
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super(CNNBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpxA-XSEvQNQ"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels * 2,\n",
        "                features[0],\n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                padding_mode=\"reflect\",\n",
        "            ),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(\n",
        "                CNNBlock(in_channels, feature, stride=1 if feature == features[-1] else 2),\n",
        "            )\n",
        "            in_channels = feature\n",
        "\n",
        "        layers.append(\n",
        "            nn.Conv2d(\n",
        "                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = torch.cat([x, y], dim=1)\n",
        "        x = self.initial(x)\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTHN_pRvvvI2"
      },
      "source": [
        "### The generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRYWUOiBvyJv"
      },
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.down = down\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x) if self.use_dropout else x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9vIuenMwKdJ"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=64):\n",
        "        super().__init__()\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down2 = Block(\n",
        "            features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down3 = Block(\n",
        "            features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down4 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down5 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down6 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(features * 8, features * 8, 4, 2, 1), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up2 = Block(\n",
        "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n",
        "        )\n",
        "        self.up3 = Block(\n",
        "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n",
        "        )\n",
        "        self.up4 = Block(\n",
        "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up5 = Block(\n",
        "            features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up6 = Block(\n",
        "            features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "        return self.final_up(torch.cat([up7, d1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsTPi_qlFmv6"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDR0J380F0Zk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e176b39d-4aa1-411d-f6bf-04b964135e49"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6fBbo-KFme2"
      },
      "source": [
        "gen = Generator(3).to(device)\n",
        "disc = Discriminator().to(device)\n",
        "\n",
        "# learning rate\n",
        "lr = 2e-3\n",
        "\n",
        "# optimizer for discriminator\n",
        "opt_disc = torch.optim.Adam(disc.parameters(), lr = lr, betas=(0.7, 0.999))\n",
        "\n",
        "# optimizer for generator \n",
        "opt_gen = torch.optim.Adam(gen.parameters(), lr = lr, betas=(0.7, 0.999))\n",
        "\n",
        "# scheduler_gen = StepLR(opt_gen, step_size = 10, gamma = 0.1)\n",
        "# scheduler_disc = StepLR(opt_disc, step_size = 1, gamma = 0.1)\n",
        "\n",
        "# Generator loss function\n",
        "L1 = nn.L1Loss()\n",
        "# discriminator loss function\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "\n",
        "# provides convenience methods for mixed precision\n",
        "g_scaler = torch.cuda.amp.GradScaler()\n",
        "d_scaler = torch.cuda.amp.GradScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i5TIDaLPhkS"
      },
      "source": [
        "import shutil\n",
        "if os.path.exists('log/fake'):\n",
        "  shutil.rmtree('log/fake')\n",
        "if os.path.exists('log/real'):\n",
        "  shutil.rmtree('log/real')\n",
        "\n",
        "writer_fake_day = SummaryWriter('log/fake/day')\n",
        "writer_real_day = SummaryWriter('log/real/day')\n",
        "writer_real_night = SummaryWriter('log/real/night')\n",
        "step = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFCcSBjk5srh"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-saJrpm_FdZz"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEgQhV9fFdEw"
      },
      "source": [
        "num_epochs = 1000\n",
        "for e in range(num_epochs):\n",
        "  for id, (day, night) in enumerate(data_loader):\n",
        "    im_day = day.to(device)\n",
        "    im_night = night.to(device)\n",
        "\n",
        "    opt_gen.zero_grad()\n",
        "    opt_disc.zero_grad()\n",
        "\n",
        "    # training discriminator for both day and night\n",
        "    with torch.cuda.amp.autocast():\n",
        "      fake_day = gen(im_night)\n",
        "      d_real = disc(im_day, im_night)\n",
        "      disc_d_real_loss = bce(d_real, torch.ones_like(d_real))\n",
        "      d_fake = disc(im_day, fake_day.detach())\n",
        "      disc_d_fake_loss = bce(d_fake, torch.zeros_like(d_fake))\n",
        "      disc_loss = (disc_d_real_loss + disc_d_fake_loss) / 2\n",
        "\n",
        "    d_scaler.scale(disc_loss).backward()\n",
        "    d_scaler.step(opt_disc)\n",
        "    d_scaler.update()\n",
        "\n",
        "    # training generator for both day and night\n",
        "    with torch.cuda.amp.autocast():\n",
        "      d_fake = disc(im_day, fake_day)\n",
        "      gen_d_loss = bce(d_fake, torch.ones_like(d_fake))\n",
        "      l1_loss = L1(fake_day, im_day) * 100\n",
        "      gen_loss = gen_d_loss + l1_loss\n",
        "    \n",
        "    g_scaler.scale(gen_loss).backward()\n",
        "    g_scaler.step(opt_gen)\n",
        "    g_scaler.update()\n",
        "\n",
        "\n",
        "    if id == 0:\n",
        "      print(\n",
        "          f\"Epoch [{e}/{num_epochs}] Batch {id}/{len(data_loader)} \\\n",
        "                Loss D: {disc_loss:.4f}, loss G: {gen_loss:.4f}\"\n",
        "      )\n",
        "      fixed_noise = torch.randn(batch_size, 3, 256, 256).to(device)\n",
        "      with torch.no_grad():\n",
        "          fake_day = gen(im_night)\n",
        "    \n",
        "          img_grid_fake_day = torchvision.utils.make_grid(fake_day,\n",
        "                                                          normalize=True)\n",
        "          img_grid_day = torchvision.utils.make_grid(im_day, normalize=True)\n",
        "          img_grid_night = torchvision.utils.make_grid(im_night, normalize=True)\n",
        "          writer_fake_day.add_image(\n",
        "              \"Fake day images\", img_grid_fake_day, global_step=step\n",
        "          )\n",
        "          writer_real_day.add_image(\n",
        "              \"Real day images \", img_grid_day, global_step=step\n",
        "          )\n",
        "          writer_real_night.add_image(\n",
        "              \"Real night images\", img_grid_night, global_step=step\n",
        "          )\n",
        "          step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LylIexwifcyd"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRGaNEBXef4o"
      },
      "source": [
        "save_path = '/content/drive/MyDrive/Colab Notebooks/models/'\n",
        "torch.save(gen.state_dict(), save_path + 'gen/gen.pth')\n",
        "torch.save(disc.state_dict(), save_path + 'disc/disc.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRPEYaCrfiKu"
      },
      "source": [
        "### Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRQ6l5Mslzr1"
      },
      "source": [
        "test_gen = Generator(3)\n",
        "test_gen.load_state_dict(torch.load(save_path + 'gen/gen.pth'))\n",
        "test_disc = torch.load(save_path + 'disc/disc.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWBygCaHfkk9"
      },
      "source": [
        "writer_test = SummaryWriter('log/test')\n",
        "step = 0\n",
        "with torch.no_grad():\n",
        "  for id, (night) in enumerate(test_loader):\n",
        "    test_gen = gen.to(device)\n",
        "    night = night.to(device)\n",
        "\n",
        "    gen_day = test_gen(night)\n",
        "    img_grid_fake_day = torchvision.utils.make_grid(gen_day, normalize=True)\n",
        "    writer_test.add_image(\"Fake day images\", img_grid_fake_day,\n",
        "                          global_step = step)\n",
        "    step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t6F7QWEm_0_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}